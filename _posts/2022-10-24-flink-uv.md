---
layout: post
title: Flink UV
author: 细雪
header-style: text
lang: en
published: true
categories:  Flink
tags:
  - Flink
---

# Flink SQL
```
INSERT INTO cumulative_UV SELECT WINDOW_end,COUNT(DISTINCT user_id) as UV FROM Table 
( CUMULATE(Table user_behavior,DESCRIPTOR(ts),INTERVAL '10' MINUTES,INTERVAL '1' DAY))) GROUP BY WINDOW_start,WINDOW_end
```

# Flink DataStream API
```
public class UVFlinkJob {
    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        //source
        DataStreamSource source = env.addSource(KafkaSource.getFlinkKafkaConsumer());


        //transform
        SingleOutputStreamOperator<UVResult> result = source
                .filter(new UVMessageFilter())
                .map(new UserBehaviorMapper())
                .map(new UVTupleMapper())
                .keyBy(0)
                .window(TumblingProcessingTimeWindows.of(Time.days(1), Time.hours(-8)))
                .trigger(ContinuousProcessingTimeTrigger.of(Time.minutes(1)))
                .aggregate(new UVAggregator(), new UVWindowResult());

        //sink
        result.print().name("Std Console Sinker");

        result.addSink(new ClickhouseSinker()).name("Clickhouse Sinker");

        //submit
        env.execute("UVFlinkJob");
    }
}
```